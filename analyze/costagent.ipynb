{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.path.dirname(os.path.abspath('.'))\n",
    "sys.path.append(current_dir)\n",
    "os.chdir(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "\n",
    "def can_skip(field_data: Any, rewritten_data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    判断某个字段是否可以跳过或直接生成\n",
    "    \n",
    "    Args:\n",
    "        field_data: dimension/measure/filter的数据\n",
    "        rewritten_data: rewritten中的数据\n",
    "    \n",
    "    Returns:\n",
    "        bool: True表示可以跳过或生成\n",
    "    \"\"\"\n",
    "    # 如果是空列表，可以跳过\n",
    "    if isinstance(field_data, list) and len(field_data) == 0:\n",
    "        return True\n",
    "\n",
    "    # 如果是None或空，可以跳过\n",
    "    if field_data is None or field_data == {}:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def can_generate_from_rewritten(field_list: List[Dict], rewritten_data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    判断字段列表是否可以从rewritten中直接生成\n",
    "    放宽匹配条件：只要核心字段信息在rewritten中任何位置出现即可\n",
    "    \n",
    "    Args:\n",
    "        field_list: config中的字段列表\n",
    "        rewritten_data: rewritten数据\n",
    "    \n",
    "    Returns:\n",
    "        bool: True表示可以直接生成\n",
    "    \"\"\"\n",
    "    if not isinstance(field_list, list) or len(field_list) == 0:\n",
    "        return False\n",
    "\n",
    "    if not rewritten_data:\n",
    "        return False\n",
    "\n",
    "    # 将rewritten整个字典转换为字符串（用于模糊搜索）\n",
    "    rewritten_str = str(rewritten_data).lower()\n",
    "\n",
    "    # 提取config中所有字段的核心信息\n",
    "    config_field_names = set()\n",
    "    for item in field_list:\n",
    "        if isinstance(item, dict):\n",
    "            value = item.get(\"字段名称\")\n",
    "            if value and isinstance(value, str) and len(value.strip()) > 0:\n",
    "                cleaned_value = value.strip().lower()\n",
    "                if len(cleaned_value) > 1:  # 只考虑长度>1的字段\n",
    "                    config_field_names.add(cleaned_value)\n",
    "            value = item.get(\"条件\")\n",
    "            if value and isinstance(value, str) and len(value.strip()) > 0:\n",
    "                cleaned_value = value.strip().lower()\n",
    "                if len(cleaned_value) > 1:\n",
    "                    config_field_names.add(cleaned_value)\n",
    "\n",
    "    if not config_field_names:\n",
    "        return False\n",
    "\n",
    "    # 检查每个字段是否在rewritten中出现\n",
    "    match_count = 0\n",
    "    for field_name in config_field_names:\n",
    "        # 模糊匹配：只要字段名在rewritten字符串中出现即可\n",
    "        if field_name in rewritten_str:\n",
    "            match_count += 1\n",
    "\n",
    "    # 如果超过一半的字段都能在rewritten中找到，认为可以生成\n",
    "    # 可以调整这个阈值\n",
    "    match_ratio = match_count / len(config_field_names)\n",
    "    return match_ratio >= 0.99  # 至少90%的字段匹配\n",
    "\n",
    "\n",
    "def analyze_single_item(data: Dict) -> Dict:\n",
    "    \"\"\"分析单个数据项\"\"\"\n",
    "    config = data.get('config', {})\n",
    "    rewritten = data.get('rewritten', {})\n",
    "\n",
    "    results = {\n",
    "        'dimension': {'status': 'unknown', 'can_generate': False},\n",
    "        'measure': {'status': 'unknown', 'can_generate': False},\n",
    "        'filter': {'status': 'unknown', 'can_generate': False}\n",
    "    }\n",
    "\n",
    "    # 分析dimension\n",
    "    dimension = config.get('dimension', [])\n",
    "    if can_skip(dimension, rewritten):\n",
    "        results['dimension'] = {'status': 'skip', 'can_generate': True}\n",
    "    elif can_generate_from_rewritten(dimension, rewritten):\n",
    "        results['dimension'] = {'status': 'generate', 'can_generate': True}\n",
    "    else:\n",
    "        results['dimension'] = {'status': 'manual', 'can_generate': False}\n",
    "\n",
    "    # 分析measure\n",
    "    measure = config.get('measure', [])\n",
    "    if can_skip(measure, rewritten):\n",
    "        results['measure'] = {'status': 'skip', 'can_generate': True}\n",
    "    elif can_generate_from_rewritten(measure, rewritten):\n",
    "        results['measure'] = {'status': 'generate', 'can_generate': True}\n",
    "    else:\n",
    "        results['measure'] = {'status': 'manual', 'can_generate': False}\n",
    "\n",
    "    # 分析filter\n",
    "    filter_data = config.get('filter', [])\n",
    "    if can_skip(filter_data, rewritten):\n",
    "        results['filter'] = {'status': 'skip', 'can_generate': True}\n",
    "    elif can_generate_from_rewritten(filter_data, rewritten):\n",
    "        results['filter'] = {'status': 'generate', 'can_generate': True}\n",
    "    else:\n",
    "        results['filter'] = {'status': 'manual', 'can_generate': False}\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_file(file_path: Path) -> List[Dict]:\n",
    "    \"\"\"分析单个文件\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # 判断数据是列表还是字典\n",
    "        if isinstance(data, list):\n",
    "            # 如果是列表，分析每一项\n",
    "            return [analyze_single_item(item) for item in data if isinstance(item, dict)]\n",
    "        elif isinstance(data, dict):\n",
    "            # 如果是字典，直接分析\n",
    "            return [analyze_single_item(data)]\n",
    "        else:\n",
    "            print(f\"Unexpected data type in {file_path}: {type(data)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {file_path}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 查找所有JSON文件\n",
    "    # workspace_path = Path(\"./data/20250916\")\n",
    "    json_files = {\"data/others/20250916_AIO_correct.json\"}\n",
    "\n",
    "    # 统计结果\n",
    "    total_stats = {\n",
    "        'dimension': {'skip': 0, 'generate': 0, 'manual': 0, 'total': 0},\n",
    "        'measure': {'skip': 0, 'generate': 0, 'manual': 0, 'total': 0},\n",
    "        'filter': {'skip': 0, 'generate': 0, 'manual': 0, 'total': 0}\n",
    "    }\n",
    "\n",
    "    analyzed_count = 0\n",
    "    total_items = 0\n",
    "\n",
    "    # 分析每个文件\n",
    "    for json_file in json_files:\n",
    "        results_list = analyze_file(json_file)\n",
    "        if results_list:\n",
    "            analyzed_count += 1\n",
    "            for results in results_list:\n",
    "                total_items += 1\n",
    "                for field in ['dimension', 'measure', 'filter']:\n",
    "                    status = results[field]['status']\n",
    "                    total_stats[field][status] += 1\n",
    "                    total_stats[field]['total'] += 1\n",
    "\n",
    "    # 输出统计结果\n",
    "    print(f\"\\n分析了 {analyzed_count} 个文件，共 {total_items} 条数据\\n\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for field in ['dimension', 'measure', 'filter']:\n",
    "        stats = total_stats[field]\n",
    "        total = stats['total']\n",
    "        if total == 0:\n",
    "            continue\n",
    "\n",
    "        can_generate_count = stats['skip'] + stats['generate']\n",
    "        generate_ratio = (can_generate_count / total * 100) if total > 0 else 0\n",
    "\n",
    "        print(f\"\\n【{field.upper()}】统计:\")\n",
    "        print(f\"  总数: {total}\")\n",
    "        print(f\"  可跳过: {stats['skip']} ({stats['skip']/total*100:.1f}%)\")\n",
    "        print(\n",
    "            f\"  可生成: {stats['generate']} ({stats['generate']/total*100:.1f}%)\")\n",
    "        print(f\"  需手动: {stats['manual']} ({stats['manual']/total*100:.1f}%)\")\n",
    "        print(f\"  ✓ 可跳过或生成比例: {generate_ratio:.1f}%\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5012fff9",
   "metadata": {},
   "source": [
    "\n",
    "分析了 6 个文件，共 616 条数据\n",
    "\n",
    "============================================================\n",
    "\n",
    "【DIMENSION】统计:\n",
    "  总数: 616\n",
    "  可跳过: 107 (17.4%)\n",
    "  可生成: 375 (60.9%)\n",
    "  需手动: 134 (21.8%)\n",
    "  ✓ 可跳过或生成比例: 78.2%\n",
    "\n",
    "【MEASURE】统计:\n",
    "  总数: 616\n",
    "  可跳过: 4 (0.6%)\n",
    "  可生成: 86 (14.0%)\n",
    "  需手动: 526 (85.4%)\n",
    "  ✓ 可跳过或生成比例: 14.6%\n",
    "\n",
    "【FILTER】统计:\n",
    "  总数: 616\n",
    "  可跳过: 0 (0.0%)\n",
    "  可生成: 244 (39.6%)\n",
    "  需手动: 372 (60.4%)\n",
    "  ✓ 可跳过或生成比例: 39.6%\n",
    "\n",
    "============================================================\n",
    "\n",
    "分析了 6 个文件，共 1152 条数据\n",
    "\n",
    "============================================================\n",
    "\n",
    "【DIMENSION】统计:\n",
    "  总数: 1152\n",
    "  可跳过: 256 (22.2%)\n",
    "  可生成: 656 (56.9%)\n",
    "  需手动: 240 (20.8%)\n",
    "  ✓ 可跳过或生成比例: 79.2%\n",
    "\n",
    "【MEASURE】统计:\n",
    "  总数: 1152\n",
    "  可跳过: 14 (1.2%)\n",
    "  可生成: 174 (15.1%)\n",
    "  需手动: 964 (83.7%)\n",
    "  ✓ 可跳过或生成比例: 16.3%\n",
    "\n",
    "【FILTER】统计:\n",
    "  总数: 1152\n",
    "  可跳过: 0 (0.0%)\n",
    "  可生成: 408 (35.4%)\n",
    "  需手动: 744 (64.6%)\n",
    "  ✓ 可跳过或生成比例: 35.4%\n",
    "\n",
    "\n",
    "分析了 6 个文件，共 2278 条数据\n",
    "\n",
    "============================================================\n",
    "\n",
    "【DIMENSION】统计:\n",
    "  总数: 2278\n",
    "  可跳过: 575 (25.2%)\n",
    "  可生成: 1142 (50.1%)\n",
    "  需手动: 561 (24.6%)\n",
    "  ✓ 可跳过或生成比例: 75.4%\n",
    "\n",
    "【MEASURE】统计:\n",
    "  总数: 2278\n",
    "  可跳过: 37 (1.6%)\n",
    "  可生成: 365 (16.0%)\n",
    "  需手动: 1876 (82.4%)\n",
    "  ✓ 可跳过或生成比例: 17.6%\n",
    "\n",
    "【FILTER】统计:\n",
    "  总数: 2278\n",
    "  可跳过: 0 (0.0%)\n",
    "  可生成: 667 (29.3%)\n",
    "  需手动: 1611 (70.7%)\n",
    "  ✓ 可跳过或生成比例: 29.3%\n",
    "\n",
    "\n",
    "分析了 1 个文件，共 4768 条数据\n",
    "\n",
    "============================================================\n",
    "\n",
    "【DIMENSION】统计:\n",
    "  总数: 4768\n",
    "  可跳过: 1293 (27.1%)\n",
    "  可生成: 1952 (40.9%)\n",
    "  需手动: 1523 (31.9%)\n",
    "  ✓ 可跳过或生成比例: 68.1%\n",
    "\n",
    "【MEASURE】统计:\n",
    "  总数: 4768\n",
    "  可跳过: 196 (4.1%)\n",
    "  可生成: 779 (16.3%)\n",
    "  需手动: 3793 (79.6%)\n",
    "  ✓ 可跳过或生成比例: 20.4%\n",
    "\n",
    "【FILTER】统计:\n",
    "  总数: 4768\n",
    "  可跳过: 0 (0.0%)\n",
    "  可生成: 965 (20.2%)\n",
    "  需手动: 3803 (79.8%)\n",
    "  ✓ 可跳过或生成比例: 20.2%\n",
    "\n",
    "============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e7a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
